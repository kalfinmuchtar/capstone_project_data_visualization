knitr::include_graphics("image/ul11.jpg")
knitr::include_graphics("image/lenna.png")
knitr::include_graphics("image/ul10.JPG")
knitr::include_graphics("assets/pca2.jpg")
knitr::include_graphics("images/pca2.jpg")
knitr::include_graphics("image/pca2.jpg")
knitr::include_graphics("image/pca1.jpg")
knitr::include_graphics("image/ul2.jpg")
knitr::include_graphics("image/knowledge check (2).png")
knitr::include_graphics("image/knowledge check (2).png")
knitr::include_graphics("image/")
#knitr::include_graphics("image/")
matrix(c(0,1,-1,0), nrow=2) %*% as.vector(c(2,3))
diag(nrow=2,ncol=2) %*% c(2,3)
set.seed(100)
x <- runif(200)
A <- data.frame(x=x, y=-x+runif(100, 1.05, 1.25))
A <- scale(A)
plot(A, cex=0.4)
mcov <- cov(A)
mcov
eigen(mcov)
# plotting eigen vector as new coordinate
slope1 <- eigen(mcov)$vectors[1,1]/eigen(mcov)$vectors[2,1]
slope2 <- eigen(mcov)$vectors[1,2]/eigen(mcov)$vectors[2,2]
plot(A, pch=19, cex=0.25, xlim=c(-1.5,1.5), ylim=c(-1.5,1.5))
lines(A[,1], A[,1] * slope1, col="blue") # PC1
lines(A[,1], A[,1] * slope2, col="green") # PC2
library(dplyr)
# read data nyc.csv
property <- read.csv("data_input/nyc.csv", stringsAsFactors = F)
# cek struktur data
glimpse(property)
# checking missing value
colSums(is.na(property))
# data wrangling
property_clean <- property %>%
select(-c(X, EASE.MENT)) %>%
mutate(BOROUGH = as.factor(BOROUGH),
NEIGHBORHOOD = as.factor(NEIGHBORHOOD),
BUILDING.CLASS.CATEGORY = as.factor(BUILDING.CLASS.CATEGORY),
BLOCK = as.factor(BLOCK),
LOT = as.factor(LOT),
BUILDING.CLASS.AT.PRESENT = as.factor(BUILDING.CLASS.AT.PRESENT),
ZIP.CODE = as.factor(ZIP.CODE),
TAX.CLASS.AT.PRESENT = as.factor(TAX.CLASS.AT.PRESENT),
LAND.SQUARE.FEET = as.integer(LAND.SQUARE.FEET),
GROSS.SQUARE.FEET = as.integer(GROSS.SQUARE.FEET),
TAX.CLASS.AT.TIME.OF.SALE = as.factor(TAX.CLASS.AT.TIME.OF.SALE),
BUILDING.CLASS.AT.TIME.OF.SALE = as.factor(BUILDING.CLASS.AT.TIME.OF.SALE),
SALE.PRICE = as.integer(SALE.PRICE),
SALE.DATE = lubridate::ymd_hms(SALE.DATE))
# re-check missing value
colSums(is.na(property_clean))
# membuang NA
property_clean <- property_clean %>%
filter(complete.cases(.)) # untuk memilih kolom yang memiliki nilai
colSums(is.na(property_clean))
# data untuk PCA
ppt <- property_clean %>%
select_if(is.numeric)
summary(ppt)
# covariance matrix
cov(ppt)
# melihat variansi yang dirangkum tiap PC
plot(prcomp(ppt))
# scaling
ppt_scale <- scale(x = ppt, center = T, scale = T)
ppt_scale %>% head()
# melihat variansi yang dirangkum tiap PC
plot(prcomp(ppt_scale))
#menggunakan data yang sudah discale
ppt_pca <- prcomp(x = ppt_scale, scale. = F)
#menggunakan data yang belum discale
ppt_pca <- prcomp(x = ppt, scale. = T)
ppt_pca$sdev
# PEMBUKTIAN
# eigen value
eigen(cov(ppt_scale))$values # from `eigen()`
ppt_pca$sdev^2 # from `prcomp()`
# eigen vector
eigen(cov(ppt_scale))$vectors
head(ppt_scale)
head(ppt_pca$x, 5)
# data hasil transformasi
ppt_scale[1:5,] %*% ppt_pca$rotation
summary(ppt_pca)
# untuk mengambil nilai pada PC yang ingin digunakan
ppt_new <- ppt_pca$x[, 1:3]
ppt_new %>% head()
summary(pca_kopi)
# your code here
library(FactoMineR)
pca_kopi <-  PCA(X = kopi_scale, # data frame
scale.unit = F,
# banyak PC yang ingin ditampilkan dan dihitung tiap observasinya
# specify indeks kolom yang tipe datanya kategorik
graph = F) # supaya saat running fungsi PCA() tidak menampilkan grafik
# your code here
kopi_scale <- scale( x= kopi, scale = T, center = T)
# your code here
kopi <- read.csv("coffee.csv", stringsAsFactors = T)
glimpse(kopi)
# your code here
kopi <- kopi %>%
select(-c(coffeeId))
head(kopi)
glimpse(kopi)
# your code here
kopi_scale <- scale( x= kopi, scale = T, center = T)
head(kopi_scale)
# your code here
library(FactoMineR)
pca_kopi <-  PCA(X = kopi_scale, # data frame
scale.unit = F,
# banyak PC yang ingin ditampilkan dan dihitung tiap observasinya
# specify indeks kolom yang tipe datanya kategorik
graph = F) # supaya saat running fungsi PCA() tidak menampilkan grafik
# summary object PCA
pca_kopi$eig
summary(pca_kopi)
# your code here
# your code here
# your code here
RNGkind(sample.kind = "Rounding")
kmeansTunning <- function(data, maxK) {
withinall <- NULL
total_k <- NULL
for (i in 2:maxK) {
set.seed(101)
temp <- kmeans(data,i)$tot.withinss
withinall <- append(withinall, temp)
total_k <- append(total_k,i)
}
plot(x = total_k, y = withinall, type = "o", xlab = "Number of Cluster", ylab = "Total within")
}
# kmeansTunning(your_data, maxK = 5)
# your code here
set.seed(101)
# your code here
# your code here
summary(pca_kopi)
# your code here
plot.pca(pca_kopi)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(FactoMineR)
# your code here
library(dplyr)
library(FactoMineR)
plot.pca(pca_kopi)
# your code here
library(dplyr)
library(FactoMineR)
plot.PCA(pca_kopi)
# your code here
pca_dimdesc <- dimdesc(pca_kopi)
# your code here
pca_dimdesc <- dimdesc(pca_kopi)
pca_dimdesc$Dim.1
# cek nilai outlier vs non outlier
ppt_small[c(32, 96, 26, 27),]
knitr::include_graphics("image/kmeans.jpg")
library(animation)
# pakai 'interval' yang lebih tinggi bila animasi terlalu cepat
# jalankan command ini di console:
# set.seed(100)
# ani.options(interval = 1)
# par(mar = c(3, 3, 1, 1.5), mgp = c(1.5, 0.5, 0))
# kmeans.ani()
# read data whiskies.txt
whisky <- read.csv("data_input/whiskies.txt", stringsAsFactors = F)
head(whisky)
# menghapus kolom yang tidak diperlukan
whisky <- whisky %>%
select(-c(RowID, Postcode, Latitude, Longitude))
# memberikan label pada baris sesuai dengan nama whisky
rownames(whisky) <- whisky$Distillery
whisky <- whisky %>%
select(-Distillery)
head(whisky)
glimpse(whisky)
# k-means with 3 clusters
set.seed(100)
whisky_kmeans <- kmeans(x = whisky, centers = 3)
whisky_kmeans$size
whisky_kmeans$centers
whisky_kmeans$cluster
whisky_kmeans
knitr::include_graphics("image/kmeans-goodness-of-fit.jpg")
# within sum of squared
whisky_kmeans$withinss
whisky_kmeans$tot.withinss
whisky_kmeans$betweenss
whisky_kmeans$betweenss/whisky_kmeans$totss
knitr::include_graphics("image/elbow-plot.jpg")
# Fungsi manual untuk elbow plot
wss <- function(data, maxCluster = 9) {
# Initialize within sum of squares
RNGkind(sample.kind = "Rounding")
set.seed(50)
SSw <- (nrow(data) - 1) * sum(apply(data, 2, var))
SSw <- vector()
for (i in 2:maxCluster) {
SSw[i] <- sum(kmeans(data, centers = i)$withinss)
}
plot(1:maxCluster, SSw, type = "o", xlab = "Number of Clusters", ylab = "Within groups sum of squares", pch=19)
}
wss(whisky)
# fungsi membuat elbow plot dari package factoextra
library(factoextra)
fviz_nbclust(whisky, kmeans, method = "wss", k.max = 9)
RNGkind(sample.kind = "Rounding") # untuk R 3.6.0 ke atas agar menyamakan dengan set.seed R 3.5
set.seed(100)
whisky_kmeans2 <- kmeans(whisky, centers = 4)
library(factoextra)
knitr::include_graphics("image/lenna.png")
# read `faceData`
load("data_input/face.rda")
# PCA dengan ncp=32
# extract new data
# make function to visualize image data
showMatrix <- function(x, title){
image(t(x[nrow(x):1,]),
xaxt = 'n', yaxt = 'n',
col = gray((0:32)/32),
main = title,
font.main=4,
cex.main=0.5
)
}
# visualize image data
par(mfrow=c(2,2), mar=c(0.5,0.5,1.5,0.5))
showMatrix(faceData, title = 'Original Image')
showMatrix(face_recon, title = 'Reconstructed: 2 dimensions')
cor(ppt_small$LAND.SQUARE.FEET, ppt_small$GROSS.SQUARE.FEET)
# PEMBUKTIAN
# eigen value
eigen(cov(ppt_scale))$values # from `eigen()`
ppt_pca$sdev^2 # from `prcomp()`
# eigen vector
eigen(cov(ppt_scale))$vectors
head(ppt_scale)
head(ppt_pca$x, 5)
# data hasil transformasi
ppt_scale[1:5,] %*% ppt_pca$rotation
summary(ppt_pca)
# untuk mengambil nilai pada PC yang ingin digunakan
ppt_new <- ppt_pca$x[, 1:3]
ppt_new %>% head()
# subset data untuk 100 data pertama
ppt_small <- head(ppt, 100)
# pca
ppt_small_pca <- prcomp(x = ppt_small, scale. = T)
# make a visualization using `biplot()`
biplot(x = ppt_small_pca, cex = 0.8)
# cek nilai outlier vs non outlier
ppt_small[c(32, 96, 26, 27),]
cor(ppt_small$LAND.SQUARE.FEET, ppt_small$GROSS.SQUARE.FEET)
cor(ppt_small$RESIDENTIAL.UNITS, ppt_small$TOTAL.UNITS)
cor(ppt_small$SALE.PRICE, ppt_small$TOTAL.UNITS)
# install.packages("FactoMineR")
library(FactoMineR)
# read data loan2017Q4.csv
loan <- read.csv("data_input/loan2017Q4.csv", stringsAsFactors = T)
glimpse(loan)
anyNA(loan)
# data wrangling
loan <- loan %>%
mutate(verified = as.factor(verified),
grdCtoA = as.factor(grdCtoA),
not_paid = as.factor(not_paid))
# kolom numerik
quantivar <- c(3:6, 9:11, 14)
# kolom kategorik
qualivar <- c(1,2,7, 8, 12, 13, 15, 16)
# scale
loan[, quantivar] <- scale(loan[, quantivar])
# PCA using FactoMineR
library(FactoMineR)
loan_pca <- PCA(X = loan, # data frame
scale.unit = F,
ncp = 8, # banyak PC yang ingin ditampilkan dan dihitung tiap observasinya
quali.sup = qualivar, # specify indeks kolom yang tipe datanya kategorik
graph = F) # supaya saat running fungsi PCA() tidak menampilkan grafik
# summary object PCA
loan_pca$eig
# visualisasi PCA dengan `plot.PCA()` - Individuals Factor Map
plot.PCA(x = loan_pca, choix = "ind", invisible = "quali", habillage = "grade", select = "contrib5")
# visualisasi PCA dengan `plot.PCA()` - Variable Factor Map
plot.PCA(x = loan_pca, choix = "var", axes = c(1, 2))
# dimdesc: dimension description
loan_desc <- dimdesc(res = loan_pca)
# variable yang berkontribusi untuk PC1
as.data.frame(loan_desc$Dim.1$quanti)
as.data.frame(loan_desc$Dim.1$quali)
as.data.frame(loan_desc$Dim.1$category)
# variable yang berkontribusi untuk PC2
as.data.frame(loan_desc$Dim.2$quanti)
plotellipses(model = loan_pca, keepvar = c(1, 2, 8))
# PCA summary
loan_pca$eig
# mengambil data hasil PCA sebanyak PC yang dibutuhkan:
loan_pca
loan_new <- as.data.frame(loan_pca$ind$coord[, 1:5])
head(loan_new)
# kita dapat reconstruct data bila menggunakan 5 PC.
loan_reconst <- reconst(loan_pca, ncp = 5)
head(loan_reconst)
# reconstruct data hasil PCA menggunakan keseluruhan PC
loan_recost_all <- reconst(loan_pca, ncp = 8)
head(loan_recost_all)
head(loan)
knitr::include_graphics("image/kmeans.jpg")
library(animation)
# pakai 'interval' yang lebih tinggi bila animasi terlalu cepat
# jalankan command ini di console:
# set.seed(100)
# ani.options(interval = 1)
# par(mar = c(3, 3, 1, 1.5), mgp = c(1.5, 0.5, 0))
# kmeans.ani()
# read data whiskies.txt
whisky <- read.csv("data_input/whiskies.txt", stringsAsFactors = F)
head(whisky)
# menghapus kolom yang tidak diperlukan
whisky <- whisky %>%
select(-c(RowID, Postcode, Latitude, Longitude))
# memberikan label pada baris sesuai dengan nama whisky
rownames(whisky) <- whisky$Distillery
whisky <- whisky %>%
select(-Distillery)
head(whisky)
glimpse(whisky)
# k-means with 3 clusters
set.seed(100)
whisky_kmeans <- kmeans(x = whisky, centers = 3)
whisky_kmeans$size
whisky_kmeans$centers
whisky_kmeans$cluster
whisky_kmeans
knitr::include_graphics("image/kmeans-goodness-of-fit.jpg")
# within sum of squared
whisky_kmeans$withinss
whisky_kmeans$tot.withinss
whisky_kmeans$betweenss
whisky_kmeans$betweenss/whisky_kmeans$totss
knitr::include_graphics("image/elbow-plot.jpg")
# Fungsi manual untuk elbow plot
wss <- function(data, maxCluster = 9) {
# Initialize within sum of squares
RNGkind(sample.kind = "Rounding")
set.seed(50)
SSw <- (nrow(data) - 1) * sum(apply(data, 2, var))
SSw <- vector()
for (i in 2:maxCluster) {
SSw[i] <- sum(kmeans(data, centers = i)$withinss)
}
plot(1:maxCluster, SSw, type = "o", xlab = "Number of Clusters", ylab = "Within groups sum of squares", pch=19)
}
wss(whisky)
# fungsi membuat elbow plot dari package factoextra
library(factoextra)
fviz_nbclust(whisky, kmeans, method = "wss", k.max = 9)
RNGkind(sample.kind = "Rounding") # untuk R 3.6.0 ke atas agar menyamakan dengan set.seed R 3.5
set.seed(100)
whisky_kmeans2 <- kmeans(whisky, centers = 4)
library(factoextra)
knitr::include_graphics("image/lenna.png")
# read `faceData`
load("data_input/face.rda")
# PCA dengan ncp=32
# extract new data
# make function to visualize image data
showMatrix <- function(x, title){
image(t(x[nrow(x):1,]),
xaxt = 'n', yaxt = 'n',
col = gray((0:32)/32),
main = title,
font.main=4,
cex.main=0.5
)
}
# visualize image data
par(mfrow=c(2,2), mar=c(0.5,0.5,1.5,0.5))
showMatrix(faceData, title = 'Original Image')
showMatrix(face_recon, title = 'Reconstructed: 2 dimensions')
# plotting eigen vector as new coordinate
slope1 <- eigen(mcov)$vectors[1,1]/eigen(mcov)$vectors[2,1]
slope2 <- eigen(mcov)$vectors[1,2]/eigen(mcov)$vectors[2,2]
plot(A, pch=19, cex=0.25, xlim=c(-1.5,1.5), ylim=c(-1.5,1.5))
lines(A[,1], A[,1] * slope1, col="blue") # PC1
lines(A[,1], A[,1] * slope2, col="green") # PC2
library(dplyr)
# read data nyc.csv
property <- read.csv("data_input/nyc.csv", stringsAsFactors = F)
# cek struktur data
glimpse(property)
# re-check missing value
colSums(is.na(property_clean))
# melihat variansi yang dirangkum tiap PC
plot(prcomp(ppt))
# scaling
ppt_scale <- scale(x = ppt, center = T, scale = T)
ppt_scale %>% head()
# melihat variansi yang dirangkum tiap PC
plot(prcomp(ppt_scale))
RNGkind(sample.kind = "Rounding")
kmeansTunning <- function(data, maxK) {
withinall <- NULL
total_k <- NULL
for (i in 2:maxK) {
set.seed(101)
temp <- kmeans(data,i)$tot.withinss
withinall <- append(withinall, temp)
total_k <- append(total_k,i)
}
plot(x = total_k, y = withinall, type = "o", xlab = "Number of Cluster", ylab = "Total within")
}
# kmeansTunning(your_data, maxK = 5)
RNGkind(sample.kind = "Rounding")
kmeansTunning <- function(data, maxK) {
withinall <- NULL
total_k <- NULL
for (i in 2:maxK) {
set.seed(101)
temp <- kmeans(data,i)$tot.withinss
withinall <- append(withinall, temp)
total_k <- append(total_k,i)
}
plot(x = total_k, y = withinall, type = "o", xlab = "Number of Cluster", ylab = "Total within")
}
kmeansTunning(pca_kopi, maxK = 5)
RNGkind(sample.kind = "Rounding")
kmeansTunning <- function(data, maxK) {
withinall <- NULL
total_k <- NULL
for (i in 2:maxK) {
set.seed(101)
temp <- kmeans(data,i)$tot.withinss
withinall <- append(withinall, temp)
total_k <- append(total_k,i)
}
plot(x = total_k, y = withinall, type = "o", xlab = "Number of Cluster", ylab = "Total within")
}
kmeansTunning(pca_dimdesc, maxK = 5)
RNGkind(sample.kind = "Rounding")
kmeansTunning <- function(data, maxK) {
withinall <- NULL
total_k <- NULL
for (i in 2:maxK) {
set.seed(101)
temp <- kmeans(data,i)$tot.withinss
withinall <- append(withinall, temp)
total_k <- append(total_k,i)
}
plot(x = total_k, y = withinall, type = "o", xlab = "Number of Cluster", ylab = "Total within")
}
kmeansTunning(x = pca_kopi, maxK = 5)
knitr::opts_chunk$set(echo = TRUE)
ts_single <- ts(data_train, start = c(2017,10, 1), end = c(2017, 12, 2),
frequency = 13 # seasonality harian
)
# data wrangling
library(dplyr)
library(tidyr)
library(lubridate)
library(padr)
library(zoo)
# Data Set
library(fpp2)
# model and evaluation
library(forecast)
library(TTR)
library(tseries)
# visualization
library(ggplot2)
library(TSstudio)
data_train <- read.csv("data/data-train.csv")
data_test <- read.csv("data/data-test.csv")
data_train
data_test
data_train <- data_train %>%
mutate(transaction_date = ymd_hms(transaction_date))
data_test <- data_test %>%
mutate(datetime = ymd_hms(datetime))
data_train
data_test
ts_single <- ts(data_train, start = c(2017,10, 1), end = c(2017, 12, 2),
frequency = 13 # seasonality harian
)
ts_single %>%
tail(13 * 7 * 12) %>%
decompose() %>%
autoplot()
data_train <- read_csv("data/data-train.csv")
data_train <- read.csv("data/data-train.csv")
data_test <- read.csv("data/data-test.csv")
data_train
data_test
data_train <- data_train %>%
mutate(transaction_date = ymd_hms(transaction_date))
data_test <- data_test %>%
mutate(datetime = ymd_hms(datetime))
data_train
data_test
ts_single <- ts(data_train, start = c(2017,10, 1), end = c(2017, 12, 2),
frequency = 13 # seasonality harian
)
ts_single %>%
tail(13 * 7 * 12) %>%
decompose() %>%
autoplot()
